{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4-zfnhCUNs_I"
      ],
      "authorship_tag": "ABX9TyOrnTwaIo1RRLi10OqsHgNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameshcodes/deep-learning-codes/blob/main/nlp_201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style=\"font-weight:bold;\">$$\\text{NLP 201: Hands On}$$</h1>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "**Natural language processing (NLP) is the ability of a computer program to understand human language**\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **What all tools we need for NLP ?**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**NLP 101: Text Preprocessing 1 - Cleaning the input**\n",
        "- Tokenization\n",
        "- Stemming\n",
        "- Lemmatization\n",
        "- Stopwords\n",
        "- Part of Speech Tagging\n",
        "- Name-Entity Recognition\n",
        "\n",
        "<br>\n",
        "\n",
        "**NLP 201: Text Prepocessing 2 - Basic(Input Text -> Vector)**\n",
        "- One hot Encoding\n",
        "- BOW\n",
        "- TF/IDF\n",
        "- Unigram, Bigram N-grams\n",
        "\n",
        "<br>\n",
        "\n",
        "**NLP 202: Text Prepocessing 3 - Advanced(Input Text -> Vector)**\n",
        "- Word-Embeddings\n",
        "- Word2Vec, Average Word2Vec\n",
        "- Glove\n",
        "\n",
        "<br>\n",
        "\n",
        "**NLP 301: Deep Learning - Basic(Modelling)**\n",
        "- RNN\n",
        "- LSTM\n",
        "- GRU\n",
        "<br>\n",
        "\n",
        "**NLP 302: Deep Learning - Advanced(Modelling)**\n",
        "- Encoder-Decoder\n",
        "- Transformers\n",
        "- Bert\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<h3 style=\"font-weight:bold;\">$$\\text{Note: Here, We will be looking at NLP 201 topics only.}$$ </h3>\n",
        "\n",
        "<center>\n",
        "\n",
        "If you are not comfortable with NLP 101 topics.\n",
        "\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "\n",
        "[Click here and get through NLP 101 first](https://colab.research.google.com/drive/1dlLpqWpKS5aTj9Efw41MwrbK06gLHQM7)\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ULq1yZItgJdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\textbf{Feature Extraction From Text}$$\n",
        "\n",
        "---\n",
        "\n",
        "**1. What is Feature Extraction From Text?**\n",
        "\n",
        " Suppose, we have textual data for sentiment analysis, but machine learning models can only understand and work with numbers and not texts. Hence we need to convert our text data into numbers and this process of converting language into numbers is called **feature extraction from text**, or **text vectorization**, or **text representation**.\n",
        "\n",
        "\n",
        "\n",
        "**2. Why do we need it ?**\n",
        "\n",
        "In solving the sentiment analysis problem mentioned above, we require high-quality features to feed into models into NLP pipeline. There's a common adage in machine learning: \"garbage in, garbage out.\" Hence, we need a method to effectively represent our text data as numerical values, ensuring a meaningful semantic representation.\n",
        "\n",
        "**What are techniques for text vectorization ?**\n",
        "- One-hot Encoding\n",
        "- Bag-of-Words\n",
        "- N-grams\n",
        "- TF/IDF\n",
        "- Some Custom Features\n"
      ],
      "metadata": {
        "id": "0hCOALvh0lpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $$\\textbf{1. One hot Encoding}$$\n",
        "\n",
        "---\n",
        "\n",
        "Imagine you have a bag of words containing all the unique words (Vocabulary) in a text. With one hot encoding, you assign each word a unique binary vector, where only one bit is 'hot' (1) and the rest are 'cold' (0). This hot bit represents the presence of that word.\n",
        "\n",
        "So, You want vector for each word? Great. Now, Let's go back to sentimant task.Suppose you have vocabulary of only 4 words in corpus i.e. you have only 4 words existing in this world and they are: **I love my cat**.\n",
        "\n",
        "Now, Before feeding into ML model you need to convert the text **I love my cat** in vectors of numbers(because algorithms work with numbers and not texts) For that one of the way to to one ohe encode the corpus. we can one-hot encode our corpus like below\n",
        "\n",
        "```\n",
        "I: [1,0,0,0]\n",
        "love: [0,1,0,0]\n",
        "my: [0,0,1,0]\n",
        "cat: [0,0,0,1]\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "So, when we want to represent the sentence **I love my cat**, we stack these codes together:\n",
        "\n",
        "```\n",
        "D = [\n",
        "[1,0,0,0],\n",
        "[0,1,0,0],\n",
        "[0,0,1,0],\n",
        "[0,0,0,1]\n",
        "]\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "We have a set of vectorized data ready for our Machine Learning model to understand the sentiment.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "4-zfnhCUNs_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$\\textbf{What are pros and cons of One-hot encoding ?}$$\n",
        "\n",
        "---\n",
        "**Pros**\n",
        "- Intuitive\n",
        "- Easy to implement\n",
        "\n",
        "**Cons**\n",
        "- Sparse vectors are created\n",
        "- No fixed size\n",
        "- Out of Vocabulary Problem\n",
        "- Can't Capture semantic meaning\n"
      ],
      "metadata": {
        "id": "thT1gHJJX6Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\textbf{Let's, one-hot encode our text. There are multiple ways. I will share a few.}$$\n",
        "\n",
        "---\n",
        "\n",
        "**i. Using sklearn library.**"
      ],
      "metadata": {
        "id": "-1h-sjEvY1bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "sentence = \"I love my cat\"\n",
        "\n",
        "words = sentence.split() # Convert the sentence into a list of words\n",
        "words_array = [[word] for word in words] #Convert list of words into a list of lists where each inner list contains a single word\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_encoded = encoder.fit_transform(words_array)\n",
        "one_hot_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gsezejWKJzW",
        "outputId": "4f6eb0ce-7858-41f5-b855-ce68afe22c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**ii. Using pandas**"
      ],
      "metadata": {
        "id": "XrwhjIyFaHfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sentence = \"I love my cat\"\n",
        "\n",
        "words = sentence.split()\n",
        "df = pd.DataFrame(columns=words)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89zerEROaHBi",
        "outputId": "0f76cf2e-1f5a-4894-de09-e209eae3ef5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [I, love, my, cat]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a87f5f8-5608-44d5-96cd-c908b741c45a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>I</th>\n",
              "      <th>love</th>\n",
              "      <th>my</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a87f5f8-5608-44d5-96cd-c908b741c45a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a87f5f8-5608-44d5-96cd-c908b741c45a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a87f5f8-5608-44d5-96cd-c908b741c45a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_5610926c-4daf-48fd-ace9-ecf8b2a5a5be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5610926c-4daf-48fd-ace9-ecf8b2a5a5be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each word and set corresponding columns to 1\n",
        "for word in words:\n",
        "    df[word] = (df.columns == word).astype(int)\n",
        "    print(df)\n",
        "    print(\"----------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPlCraV4arT3",
        "outputId": "e2551bfc-dc48-411b-8b32-8a6322a8702d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   I love   my  cat\n",
            "0  1  NaN  NaN  NaN\n",
            "1  0  NaN  NaN  NaN\n",
            "2  0  NaN  NaN  NaN\n",
            "3  0  NaN  NaN  NaN\n",
            "----------------\n",
            "   I  love   my  cat\n",
            "0  1     0  NaN  NaN\n",
            "1  0     1  NaN  NaN\n",
            "2  0     0  NaN  NaN\n",
            "3  0     0  NaN  NaN\n",
            "----------------\n",
            "   I  love  my  cat\n",
            "0  1     0   0  NaN\n",
            "1  0     1   0  NaN\n",
            "2  0     0   1  NaN\n",
            "3  0     0   0  NaN\n",
            "----------------\n",
            "   I  love  my  cat\n",
            "0  1     0   0    0\n",
            "1  0     1   0    0\n",
            "2  0     0   1    0\n",
            "3  0     0   0    1\n",
            "----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $$\\textbf{2. Bag of Words}$$\n",
        "\n",
        "---\n",
        "The Bag of Words model represents text by counting word occurrences i.e how many time a word appeared in corpus, disregarding grammar and order.\n",
        "\n",
        "**Note:** It performs good on tasks like sentiment analysis and classification but may lose context and meaning.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Steps**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Step 1:** **Tokenize the corpus**:\n",
        "\n",
        "Let's have a corpus with vocabulary, **I love my cat oscar a lot**. Note that This corpus has 7 length vocabulary.\n",
        "\n",
        "\n",
        "Let's go back to **I love my cat** example. We will make a bag of word for this with respect to above vocabulary. After tokenization, break the sentence into words as:\n",
        "<center>\n",
        "\n",
        "**\"I\"**, **\"love\"**, **\"my\"**, **\"cat\"**\n",
        "\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "\n",
        "**Step 2:Vocabulary Creation**\n",
        "\n",
        "Create a list of unique words in the phrase: **[\"I\", \"love\", \"my\", \"cat\"]**\n",
        "\n",
        "<br>\n",
        "\n",
        "**Step 3: Counting Word Occurrences**\n",
        "\n",
        "Count how many times each word appears:\n",
        "\n",
        "- **I**: 1 time\n",
        "- **love**: 1 time\n",
        "- **my**: 1 time\n",
        "- **cat**: 1 time\n",
        "- **Oscar**: 0 time\n",
        "- **a**: 0 time\n",
        "- **lot**: 0 time\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**Step 4: Vector Representation**\n",
        "\n",
        "Since each word in **I love my cat** appears once and **Oscar a lot** doesn't appear in the example, the Bag of Words vector would look like:\n",
        "\n",
        "<center>\n",
        "\n",
        "| I | love | my | cat | Oscar | a | lot |\n",
        "|---|------|----|-----|-------|---|-----|\n",
        "| 1 |  1   | 1  |  1  |   0   | 0 |  0  |\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "So the vector of BOW will be: $$[1,1,1,1,0,0,0]$$\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Note that**, the vocabulary was of 7 length, the BOW vector are also are 7 length"
      ],
      "metadata": {
        "id": "yKI3L2uxcrFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Lets see how a data frame for BOW is created\n",
        "</h2>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "Consider same corpus as above with vocabulary, **I love my cat oscar a lot**.\n",
        "\n",
        "<br>\n",
        "$$\\text{Below I have created few sencence and their BOW vectors.}$$\n",
        "\n",
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "| Sno | Sentence                            | I | love | my | cat | Oscar | a | lot |\n",
        "|-----|-------------------------------------|---|------|----|-----|-------|---|-----|\n",
        "| 1   | **I love my cat Oscar a lot**       | 1 |  1   | 1  |  1  |   1   | 1 |  1  |\n",
        "| 2   | **I love Oscar a lot**              | 1 |  1   | 0  |  0  |   1   | 1 |  1  |\n",
        "| 3   | **I love my cat**                   | 1 |  1   | 1  |  1  |   0   | 0 |  0  |\n",
        "| 4   | **Oscar my cat oscar**              | 0 |  0   | 0  |  1  |   2   | 0 |  0  |\n",
        "| 5   | **love cat love cat cat**           | 0 |  2   | 0  |  3  |   0   | 0 |  0  |\n",
        "| 6   | **love cat my love cat**            | 0 |  2   | 1  |  0  |   0   | 0 |  0  |\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "In above dataframe for example **5**, ***love cat love cat cat***, The appearance of words are as:\n",
        "\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "\n",
        "| Word   | Count |\n",
        "|--------|-------|\n",
        "| I      |   0   |\n",
        "| love   |   2   |\n",
        "| my     |   0   |\n",
        "| cat    |   3   |\n",
        "| Oscar  |   0   |\n",
        "| a      |   0   |\n",
        "| lot    |   0   |\n",
        "\n",
        "</center>\n",
        "<br>\n",
        "<br>\n",
        "Hence, the Bag of Vector for this will be: $$[0, 2, 0, 3, 0, 0, 0]$$\n"
      ],
      "metadata": {
        "id": "emLwOq9skqNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Let's, learn how create BOW vectors in python**\n",
        "\n",
        "\n",
        "In the dataframe above, sentiments have been randomly assigned.\n"
      ],
      "metadata": {
        "id": "1PbZl4yXsJd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Sentence': [\n",
        "        'I love my cat Oscar a lot',\n",
        "        'I love Oscar a lot',\n",
        "        'I love my cat',\n",
        "        'Oscar my cat oscar',\n",
        "        'love cat love cat cat',\n",
        "        'love cat my love cat'\n",
        "    ],\n",
        "    'Sentiment': [\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'neutral',\n",
        "        'neutral',\n",
        "        'neutral'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "jexv_WGfcvy0",
        "outputId": "df3a1950-d74a-4d2d-c873-37f53276c872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Sentence Sentiment\n",
              "0  I love my cat Oscar a lot  positive\n",
              "1         I love Oscar a lot  positive\n",
              "2              I love my cat  positive\n",
              "3         Oscar my cat oscar   neutral\n",
              "4      love cat love cat cat   neutral\n",
              "5       love cat my love cat   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80e4b860-5319-4221-8ec5-340d649077c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love my cat Oscar a lot</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Oscar a lot</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I love my cat</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Oscar my cat oscar</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>love cat love cat cat</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>love cat my love cat</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80e4b860-5319-4221-8ec5-340d649077c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80e4b860-5319-4221-8ec5-340d649077c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80e4b860-5319-4221-8ec5-340d649077c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-308909e5-c760-4899-9699-3678de222cd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-308909e5-c760-4899-9699-3678de222cd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-308909e5-c760-4899-9699-3678de222cd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0c0937e4-1ebe-4d15-839f-660958b81099\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0c0937e4-1ebe-4d15-839f-660958b81099 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"I love my cat Oscar a lot\",\n          \"I love Oscar a lot\",\n          \"love cat my love cat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note: This type of dataset is commonly used for sentiment classification data.**"
      ],
      "metadata": {
        "id": "yOzEn-gKtSyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow_vectors = bow_vectorizer.fit_transform(df['Sentence'])"
      ],
      "metadata": {
        "id": "iNbu3EmmshRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "We can get the for a vector index represent what word using **vocabulary_** method\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "is2yFPMLwBXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWh51KifwUBc",
        "outputId": "c668751a-21d3-47cf-c199-249e35d82106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love': 2, 'my': 3, 'cat': 0, 'oscar': 4, 'lot': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**Note:** We originally had a vocabulary of 7 words, but after using CountVectorizer, our vocabulary was reduced to 5 words. This happened because CountVectorizer remove words that are stop words.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let view the **bow_vectors**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vnZ06ZhXx1f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt43DBivxmWs",
        "outputId": "eec66b74-619d-45a7-d200-a93da66e16a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x5 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 19 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Tt is currently an compressed as object. To convert this object into matrix.\n",
        "\n",
        "\n",
        "> Use **toarray()** method\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "s0SJrfltuW6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow_vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVtN3EIRuWe1",
        "outputId": "ee2efef1-2aa8-46f7-fc7f-1b523098f483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1]\n",
            " [0 1 1 0 1]\n",
            " [1 0 1 1 0]\n",
            " [1 0 0 1 2]\n",
            " [3 0 2 0 0]\n",
            " [2 0 2 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Note:** We can also get bow vector for individual sentences using indexing.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uS1z7FQAvMjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow_vectors[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ObtomYuN0i",
        "outputId": "8fa34209-9f88-4189-c3ea-9d5332120f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow_vectors[1].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZRk_T5OvJSy",
        "outputId": "e17778e0-a679-48e4-a049-0c96db478967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Let transform a new sentence **love my dog oscar love oscar oscar**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q1RhUFlvzAle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# {'love': 2, 'my': 3, 'cat': 0, 'oscar': 4, 'lot': 1} --------------> this is the hashing for vectors\n",
        "document = \"love my dog oscar love oscar oscar\"\n",
        "bow_vectorizer.transform([document]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCdDNuGwy_-E",
        "outputId": "3d4639e9-1fd6-4abe-c841-525aecca7dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 2, 1, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "- The vector was created using the frequency of love, my, and oscar. The word dog was ignored because it was not present during training. This demonstrates how the Bag of Words (BoW) model handles out-of-vocabulary words in the data(simply by ignoring).\n",
        "\n",
        "Consider exploring [WordVectorizer module in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "gXJi1Esd1QRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problems in one hot encoding solved by Bag of Word**\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "**1. Fix word size, no. of words in document doesn't matter.**\n",
        "\n",
        "Consider a corpus with vocabulary **\"I love my cat\"**. Then we can vectorize below documents as\n",
        "\n",
        "- I love my cat ------>  **[1, 1, 1, 1]**\n",
        "\n",
        "- I love cat ------------->**[1, 1, 0, 1]**\n",
        "\n",
        "Note that, both document will have same size BOW vector.\n",
        "\n",
        "<br>\n",
        "\n",
        "**2. It also handle out of vocabulary error in new sentence by simply ignoring the word while creating bag of word vector.**\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "WlD7YfQB6fGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cons in Bow**\n",
        "\n",
        "---\n",
        "\n",
        "**1. Ignoring the OOV word in new sentence might lose the meaning in sentence.**\n",
        "\n",
        "**For example**:\n",
        "\n",
        "We have\n",
        "- I love cat ------------->**[1, 1, 0, 1]**\n",
        "\n",
        "Now, if we convert the sententce **I don't love cat** into BOW, and since the word **don't**  was not there during training. Then\n",
        "\n",
        "- I don't love cat ------------->**[1, 1, 0, 1]**\n",
        "\n",
        "Both **I love cat** and **I don't love cat** will have same vector in that case, which is wrong because both sentence have opposite meaning and infromation which **don't** could provide is lost.\n",
        "\n",
        "<br>\n",
        "\n",
        "**2. Despite the representation as Bag-of-Words (BOW), vectors remain sparse. When the vocabulary is extensive, even after vectorizing a sentence, numerous elements in the vector will retain a value of 0.**\n",
        "\n",
        "<br>\n",
        "\n",
        "**3. Not Considering ordering of Sentence is an issue**"
      ],
      "metadata": {
        "id": "KMAneNI66j9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $$\\textbf{Core Idea of bag of words}$$\n",
        "---\n",
        "\n",
        "The Bag of Words (BoW) model simply counts how often each word shows up in a corpus, without caring about grammar or the order of words. Then, it convert each document in corpus into a list showing how many times each word appears."
      ],
      "metadata": {
        "id": "VdsoVLukpMq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $$\\text{N-grams: Bag of N-grams}$$\n",
        "---\n",
        "\n",
        "- Earlier in one-hot encoding or bag-of-words, the vocabulary consisted of single words, and the problem with that was we could not exploit the ordering in the sentence.  We were not able to capture the semantic meaning in sentences because ordering is very important in language.\n",
        "\n",
        "- We solve this problem with N-grams, where the **vocabulary consists of sequences of N words.**\n",
        "\n",
        "<br>\n",
        "\n",
        "**For example:**\n",
        "\n",
        "The tokenization for **I love my cat oscar a lot** using bi-gram will be: **I love / love my /my cat/ cat oscar/ oscar a/ alot**. Its like sliding window of size 2.\n",
        "\n",
        "**Note:** I have not considered existance of stopwords.\n",
        "\n",
        "<br>\n",
        "$$\\text{Some examples of how N-grams will look after tokenzation and encoding into numbers.}$$\n",
        "\n",
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "| Sentence                | I love | love my | my cat | cat oscar | oscar a | a lot | Ngram vector       |\n",
        "|-------------------------|--------|---------|--------|-----------|---------|-------|--------------------|\n",
        "| I love my cat oscar a lot | 1      | 1       | 1      | 1         | 1       | 1     | [1, 1, 1, 1, 1, 1] |\n",
        "| I love cat a lot         | 1      | 0       | 0      | 0         | 0       | 1     | [1, 0, 0, 0, 0, 1] |\n",
        "| I love my cat oscar         | 1      | 1       | 1      | 1         | 0       | 0     | [1, 1, 1, 1, 0, 0] |\n",
        "\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note that:** Bag of Words is a special case of bag of N-grams i.e it is unigram\n",
        "\n",
        "In sklearn's CountVectorizer() pass\n",
        "\n",
        "- **ngram_range = (1,1)**: only BOW or unigrams\n",
        "- **ngram_range = (2,2)**: only bi-gram\n",
        "- **ngram_range = (1,2)**: both uni-gram/BOW\n",
        "- **ngram_range = (1,3)**: uni-gram/BOW and bigrams, and trigrams\n",
        "- **ngram_range = (2,3)**: both bi-grams, and trigrams\n",
        "- **ngram_range = (2,3)**: only tri-grams\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<h3>\n",
        "Pros and Cons of N-grams\n",
        "</h3>\n",
        "\n",
        "---\n",
        "\n",
        "| Pros                                        | Cons                                                  |\n",
        "|---------------------------------------------|-------------------------------------------------------|\n",
        "| 1. Captures local context and dependencies. | 1. Increased dimensionality of vocabulary with increase N        |\n",
        "| 2. Captures some semantic meaning  | 2. Data sparsity issues with higher-order N-grams.    |\n",
        "|    information.                             | 3. No solution for handling out of vocabulary **OOV** error                |\n",
        "| 3. Can handle variable-length sequences.    |                                                       |\n",
        "                                   |\n"
      ],
      "metadata": {
        "id": "k6Dy-6vbECpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $$\\text{Lets see N-grams in action}$$\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RPWd2jNNHCGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bi_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "document = [\"I love my cat oscar a lot\"]\n",
        "\n",
        "bi_vectorizer.fit(document) # it take document in a list of sentences, don't feed sentences directly.\n",
        "\n",
        "bi_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM7K6QDpDZWm",
        "outputId": "25755613-4c8d-4ed3-aeae-000d7add3939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love my': 1, 'my cat': 2, 'cat oscar': 0, 'oscar lot': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "- **love my: 1:** This indicates that the bigram \"love my\" is assigned the index 1.\n",
        "- **my cat: 2:** This indicates that the bigram \"my cat\" is assigned the index 2.\n",
        "- **cat oscar: 0:** This indicates that the bigram \"cat oscar\" is assigned the index 0.\n",
        "- **oscar lot: 3:** This indicates that the bigram \"oscar lot\" is assigned the index 3.\n"
      ],
      "metadata": {
        "id": "moFLwKxkFARA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bi_vectorizer.transform([\"I love my cat oscar a lot\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb2md8QTESn7",
        "outputId": "c1a47ab6-d6bb-4e40-9311-4c47a9f3e010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_vectorizer.transform([\"I love cat a lot\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wsP9WPUGG6s",
        "outputId": "7c14a64f-48ff-4ce9-fb84-242943ae998f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_vectorizer.transform([\"I love my cat a lot\"]).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv3wMbOGGP1O",
        "outputId": "e0963b1a-1c36-4c12-f475-9d0b87043beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Lets see how N-gram works with multiple sentences.\n",
        "</h1>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2Rwj6Ib3ESNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Sentence': [\n",
        "        'I love my cat Oscar a lot',\n",
        "        'I love Oscar a lot',\n",
        "        'I love my cat',\n",
        "        'Oscar my cat oscar',\n",
        "        'love cat love cat cat',\n",
        "        'love cat my love cat'\n",
        "    ],\n",
        "    'Sentiment': [\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'neutral',\n",
        "        'neutral',\n",
        "        'neutral'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "-HQ5TE_B-DZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35a04c7-e6de-41ab-a3bd-a4ed94d65458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Sentence Sentiment\n",
            "0  I love my cat Oscar a lot  positive\n",
            "1         I love Oscar a lot  positive\n",
            "2              I love my cat  positive\n",
            "3         Oscar my cat oscar   neutral\n",
            "4      love cat love cat cat   neutral\n",
            "5       love cat my love cat   neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "bigram_vectorizer.fit_transform(df['Sentence'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDTgXGsiBECM",
        "outputId": "aa277919-9296-4ede-95df-9a4db38f0523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x11 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 17 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nmwod56Cbjc",
        "outputId": "a92432df-5266-4167-f42d-896c3db4a07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'love my': 5,\n",
              " 'my cat': 7,\n",
              " 'cat oscar': 3,\n",
              " 'oscar lot': 9,\n",
              " 'love oscar': 6,\n",
              " 'oscar my': 10,\n",
              " 'love cat': 4,\n",
              " 'cat love': 1,\n",
              " 'cat cat': 0,\n",
              " 'cat my': 2,\n",
              " 'my love': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_vectorizer.transform(['I love my cat oscar a lot']).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onag7opmCcKG",
        "outputId": "2c04d91e-e74e-4bdd-9016-d600e27f6d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $$\\text{TF-IDF}$$\n",
        "\n",
        "---\n",
        "\n",
        "**Problem with one-hot encoding, Bag of words, N-grams:**  \n",
        "\n",
        "All of these three text representation techniques assign equal importance to all the tokens. They assign 0 if a word is absent in the sentence, and 1 if the word is present.\n",
        "\n",
        "**TF-IDF solves this problem by assigning different values to different words.**\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "$$\\text{How does TF-IDF do it ?}$$\n",
        "\n",
        "---\n",
        "TF-IDF assigns weights to words based on how frequently they appear in a document compared to their frequency across all documents in the dataset.\n",
        "\n",
        "**It uses two measures to calcuate importance:**\n",
        "- Term Frequency (TF)\n",
        "- Inverse Document Frequency (IDF)\n",
        "\n",
        "\n",
        "![TF-IDF Formula](https://ptime.s3.ap-northeast-1.amazonaws.com/media/natural_language_processing/text_feature_Engineering/tf-idf-formula.PNG)\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Logic for TF-IDF is simple:**\n",
        "\n",
        "It assigns higher weightage to those word in document whose frequency is more in that particular document but are rare across corpus.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "$$\\textbf{Pros and Cons of TF-IDF}$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<center>\n",
        "\n",
        "| Pros                               | Cons                               |\n",
        "|------------------------------------|------------------------------------|\n",
        "| Weighted Representation of words  | High dimensional vectors          |\n",
        "| Robustness to Stop Words          | Lack of semantic meaning          |\n",
        "| Interpretability                  | Produces sparse vectors           |\n",
        "| Widely Used                       | Can't handle **OOV** words          |\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "aRTSURDrKW-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $$\\text{Lets see Tf-Idf in Action.}$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "THVAVJHBTfMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Sentence': [\n",
        "        'I love my cat Oscar a lot',\n",
        "        'I love Oscar a lot',\n",
        "        'I love my cat',\n",
        "        'Oscar my cat oscar',\n",
        "        'love cat love cat cat',\n",
        "        'love cat my love cat'\n",
        "    ],\n",
        "    'Sentiment': [\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'neutral',\n",
        "        'neutral',\n",
        "        'neutral'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_3kastYKffv",
        "outputId": "bff96d9e-9406-4a8a-b94c-7cade624ebc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Sentence Sentiment\n",
            "0  I love my cat Oscar a lot  positive\n",
            "1         I love Oscar a lot  positive\n",
            "2              I love my cat  positive\n",
            "3         Oscar my cat oscar   neutral\n",
            "4      love cat love cat cat   neutral\n",
            "5       love cat my love cat   neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_vectorizer.fit_transform(df['Sentence']).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKqGv4mvT_xC",
        "outputId": "d562b125-9091-4a2c-ec06-23ef5738c9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35970394, 0.57573099, 0.35970394, 0.41652649, 0.48607166],\n",
              "       [0.        , 0.68955073, 0.43081598, 0.        , 0.58216611],\n",
              "       [0.54710234, 0.        , 0.54710234, 0.63352827, 0.        ],\n",
              "       [0.32199391, 0.        , 0.        , 0.3728594 , 0.87022743],\n",
              "       [0.83205029, 0.        , 0.5547002 , 0.        , 0.        ],\n",
              "       [0.65438863, 0.        , 0.65438863, 0.37888131, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "<h2>\n",
        "Note that\n",
        "</h2>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " IDF values are consistent across the entire corpus, unlike TF, which varies from document to document. Let's get out the IDF vector for each token. IDF measures how important a word is within a collection of documents.\n"
      ],
      "metadata": {
        "id": "DuHXLZ46W841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_vectorizer.idf_)\n",
        "print(tfidf_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81PuW8VvWuYa",
        "outputId": "0f053848-8344-4137-a3ac-890cfb816db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.15415068 1.84729786 1.15415068 1.33647224 1.55961579]\n",
            "['cat' 'lot' 'love' 'my' 'oscar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "- The token **cat** has an IDF value of approximately **1.154**.\n",
        "- The token **lot** has an IDF value of approximately **1.847**.\n",
        "- The token **love** has an IDF value of approximately **1.154**.\n",
        "- The token **my** has an IDF value of approximately **1.336**.\n",
        "- The token **oscar** has an IDF value of approximately **1.560**.\n",
        "\n",
        "Here,  these IDF values help us understand the significance of each token across the corpus. Tokens like \"lot\" and \"oscar\" have higher IDF values, suggesting they are relatively more unique or rare compared to tokens like \"cat\" and \"love,\" which have lower IDF values, indicating they are more common across the corpus.\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<h3>\n",
        "Remark\n",
        "</h3>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**You'll get bigger IDF values in sklearn's TF-IDF because they have a little different Implementation of TF-IDF than original TF-IDF**\n",
        "\n",
        "<br>\n",
        "\n",
        "![IF-IDF](https://miro.medium.com/v2/resize:fit:716/1*xFbKEALUXjrWV_4nwSDBOg.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Reasoning**\n",
        "\n",
        "- **Addition of 1 to numerator and denominator:** Ensures non-zero IDF for terms with zero document frequency, avoiding division by zero errors.\n",
        "\n",
        "- **Addition of 1 orginal TF-IDF :** Prevents terms in all documents from having zero IDF, ensuring no term is disregarded entirely in TF-IDF calculation."
      ],
      "metadata": {
        "id": "8d9W4jB_YByA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### $$\\text{Why do we take log in IDF calculation?}$$\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "G-B3KpJrdHtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Imagine you're looking at two words: **cat** and **dog**, in a bunch of documents.\n",
        "\n",
        "Let's say\n",
        "- **dog** appears in 500 out of 1,000 documents\n",
        "-  **cat** only shows up in 10 of 1000 documents.\n",
        "\n",
        "\n",
        "**<u>If we calculate IDF without log, we get:</u>**\n",
        "\n",
        "\n",
        "$$IDF(dog) = \\frac{1000}{500} = 2$$\n",
        "\n",
        "$$IDF(cat) = \\frac{1000}{10} = 100$$\n",
        "\n",
        "<br>\n",
        "\n",
        "-  Without logarithms, the IDF values for **dog** and **cat** are very different: **dog** has an IDF of 2, while **cat** has an IDF of 100. This discrepancy highlights that **cat** is considered much rarer across the document corpus compared to **dog**.\n",
        "\n",
        "- The unbalanced representation of IDF values can skew TF-IDF scores, favoring terms like **cat** that are rare across documents. This dominance of rare terms like **cat** can make the importance of more frequent terms like **cat** almost neighligible in TF-IDF.\n",
        "\n",
        "-  Taking log helps to mitigate this imbalance by scaling down the impact of exteme IDF values."
      ],
      "metadata": {
        "id": "Ojp9NoWXkQLW"
      }
    }
  ]
}