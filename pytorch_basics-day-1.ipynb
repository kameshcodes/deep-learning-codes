{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUN5SuFM860e5nD/UMUAvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kameshcodes/deep-learning-codes/blob/main/pytorch_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\textbf{Pytorch Day 1}$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nmiNs-NXqf9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. $\\textbf{Tensor Basics}$\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### $\\textbf{But Why Tensors and not arrays or dataframes ?}$\n",
        "\n",
        "\n",
        "While NumPy arrays and Pandas dataframes has been useful for numerical computations and data manipulation, PyTorch tensors offer several advantages for machine learning, especially in deep learning while training neural networks:\n",
        "\n",
        "#### GPU Acceleration:\n",
        "- **Tensors**: PyTorch tensors can be easily transferred to GPUs, enabling faster computations crucial for training large neural networks.\n",
        "- **NumPy Arrays/Pandas DataFrames**: Primarily designed for CPU operations. GPU support via libraries like CuPy is less seamless than in PyTorch.\n",
        "\n",
        "#### - Automatic Differentiation:\n",
        "- **Tensors**: PyTorch's `autograd` package works with tensors to automatically compute gradients, essential for backpropagation in neural network training.\n",
        "- **NumPy Arrays/Pandas DataFrames**: Do not inherently support automatic differentiation, making manual gradient calculations cumbersome and error-prone.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "rQTx0xfmugTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "random.seed(1) #for reprodicibility"
      ],
      "metadata": {
        "id": "B3-XcANeu-WM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.1 Tensor Creation}$"
      ],
      "metadata": {
        "id": "b77RTJqH3HKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{1.1.1 Empty Tensors}$\n"
      ],
      "metadata": {
        "id": "0_eBb3ORxfQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54v-GRiYvSgq",
        "outputId": "3985f3dd-77af-488d-e69d-f968332c094c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0622e-19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{This empty tensor means it will intialize an empty tensor, basically a garbage value}$"
      ],
      "metadata": {
        "id": "B5C1hA5Xvul2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZSDCFqyv2Aa",
        "outputId": "d92b5cce-533a-4ada-c2dd-a615b99fba4d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.2822e-05,  3.2802e-41, -1.7301e+28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "$\\textbf{Lets make multidimensional tensor}$"
      ],
      "metadata": {
        "id": "juKGOVhlwPww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeZjNSD9wPBG",
        "outputId": "0ef92057-a637-482a-d6a4-c19d70ebadca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000e+00,  0.0000e+00,  2.3028e-05,  3.2802e-41],\n",
            "        [ 4.1439e-06,  3.2802e-41, -1.1831e+38,  4.3471e-41],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYJfeCdjw09p",
        "outputId": "62b7c42b-aa99-4595-ba2d-0fc8f1c57f2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2.3036e-05,  3.2802e-41,  2.3040e-05,  3.2802e-41],\n",
            "         [ 1.1210e-43,  0.0000e+00,  8.9683e-44,  0.0000e+00],\n",
            "         [-1.7961e-38,  3.2809e-41,  2.1707e-18,  4.5447e+30]],\n",
            "\n",
            "        [[ 7.0062e+22,  2.1715e-18,  4.5447e+30,  7.0062e+22],\n",
            "         [ 2.1707e-18,  1.9284e+31,  3.2314e-18,  1.8692e+20],\n",
            "         [ 2.0179e-43,  0.0000e+00,  1.7937e-43,  0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{1.1.2 Tensors of zeros}$"
      ],
      "metadata": {
        "id": "VcMr92NSxz73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros(3)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_OednKdw5xE",
        "outputId": "eed07523-866d-42fd-963d-3623a29f3dad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros(3,4)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikNGYx2AyO6x",
        "outputId": "515467e3-1c72-42f5-bc8c-51551a15d145"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros(2,3,4)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpron_f2yl4g",
        "outputId": "8c8ad1be-52bc-4f41-c857-3d08b7705724"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  $\\text{1.1.3 Tensor of ones and torch dtypes}$"
      ],
      "metadata": {
        "id": "SJehXGdJzDzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(3)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRYxOUjUzDI6",
        "outputId": "c4bf6769-9a53-48aa-df7f-1d3688d6b327"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(z.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54oYmonnzft7",
        "outputId": "2a0096af-65fd-4254-dc57-d4ffbe980709"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{By default, The datatype inside the tensors are float 32.}$\n",
        "\n"
      ],
      "metadata": {
        "id": "mg5Z3jb-z4E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguEfq1Az0uP",
        "outputId": "ce5a2101-8c64-4968-8045-2ca63c3ad81f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{You can see the same with tensor of zeros as well. But, We can change this}$\n",
        "\n",
        "**Pass:** `dtype=torch.datatype`\n",
        "\n"
      ],
      "metadata": {
        "id": "OH5WAxpPzpLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(3, dtype=torch.int32)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qzyR6P70TcW",
        "outputId": "df3c944b-ae9a-4f91-f415-cdf63236fbe3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(3, dtype=torch.double)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97pLeEZq0QyL",
        "outputId": "e7bd7ca5-f912-4315-ef2e-358eaed360bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(3, dtype=torch.float32)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfuuV5I40Rzk",
        "outputId": "c2ebb2f8-0665-46e9-9d2a-da36aca04a83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{1.1.4 size()}$"
      ],
      "metadata": {
        "id": "XrL5riOo1FNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(3, dtype=torch.double)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdQMqVAW1EKH",
        "outputId": "c9a0025a-754d-414d-d153-7f0085d5c04b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Heogt5OG1D9F",
        "outputId": "b7bd29c4-ef38-4ad4-caf4-cb4a6a0a9f3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.size>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " size$\\text{ does not work the was in pandas but here you write it a method like }$ `z.size()`"
      ],
      "metadata": {
        "id": "JnqLQRhH1UV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh7CdwlF1Txp",
        "outputId": "ce387d39-ad66-40d9-a4df-a215c8748bbb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.ones(5, 3, dtype=torch.double)\n",
        "z.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZkhQcwf1D5s",
        "outputId": "171c6fca-e43d-4eb7-b9b4-c05dca8d9ef5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.5 $\\text{Creating Tensor for Data}$"
      ],
      "metadata": {
        "id": "FZIg3OCH2JHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_data = [1,2,3,4]\n",
        "tensor_data = torch.tensor(list_data, dtype=torch.float16) # Note: You can change type of data as well when you are converting\n",
        "print(tensor_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f18AvAcP2IqC",
        "outputId": "fcc8c4d7-d980-48b7-ce11-dc601aa48a87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.2 Tensor Operations}$"
      ],
      "metadata": {
        "id": "QYOrJuIn3lQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $\\text{1.2.1 Addition of Tensors}$"
      ],
      "metadata": {
        "id": "deeG6q7V5UJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2) # rand create a random tensor\n",
        "y = torch.ones(2,2, dtype=torch.int16) # creates a tensor of 1's\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g_qD_Ny2ET3",
        "outputId": "1b6867fb-0aa9-4019-b696-acd40d7daef2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4623, 0.7468],\n",
            "        [0.6805, 0.6214]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x+y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h3LRG0E2EQS",
        "outputId": "15dde2f8-2d57-4767-d239-0d27386bdd2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4623, 1.7468],\n",
            "        [1.6805, 1.6214]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.add(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31AjCDIi2ENR",
        "outputId": "6bf107db-190a-4318-eb4d-484406db39ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4623, 1.7468],\n",
            "        [1.6805, 1.6214]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Inplace Addition}$"
      ],
      "metadata": {
        "id": "a6FNPg415pVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.add_(y)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJxbr1Fm5uS6",
        "outputId": "2abfb4a6-e9fe-4c5f-e921-7762a5808b14"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4623, 1.7468],\n",
            "        [1.6805, 1.6214]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $\\text{1.2.2 Substraction of Tesors}$"
      ],
      "metadata": {
        "id": "9TpG3H7459rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2) # rand create a random tensor\n",
        "y = torch.ones(2,2, dtype=torch.int16) # creates a tensor of 1's\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2B493p06f2x",
        "outputId": "31ea33c7-7daf-451c-f40e-6dedf6e4a9a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8406, 0.1513],\n",
            "        [0.3079, 0.8812]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x-y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOvU9VCj2EKG",
        "outputId": "1f2009e4-8f83-45a0-b596-a127be0a70c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1594, -0.8487],\n",
            "        [-0.6921, -0.1188]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.sub(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAG5hWTs2EHE",
        "outputId": "a86e2760-7935-471e-d6d5-a84b20274c28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1594, -0.8487],\n",
            "        [-0.6921, -0.1188]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.sub_(y)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsD2uFmX2EER",
        "outputId": "f6c178c4-61bb-483f-8ec9-77c2b7584997"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1594, -0.8487],\n",
            "        [-0.6921, -0.1188]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{1.2.3 ElementWise Product of Tesors}$"
      ],
      "metadata": {
        "id": "8MIdk3YQ7AGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2) # rand create a random tensor\n",
        "y = torch.ones(2,2, dtype=torch.int16) # creates a tensor of 1's\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtbomWPC2EBa",
        "outputId": "7a2384b5-60a5-4199-a64e-7158ad07b8ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9857, 0.0098],\n",
            "        [0.2819, 0.5824]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=x*y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFYlUoQx2D-f",
        "outputId": "dade4965-09b7-4591-9425-9d830d3cde42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9857, 0.0098],\n",
            "        [0.2819, 0.5824]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.mul(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVzJqVCP2D7N",
        "outputId": "0d4cfc7d-52cc-4d47-d2c4-ff553fde1815"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9857, 0.0098],\n",
            "        [0.2819, 0.5824]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.mul_(y)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS-wHqZK7dYE",
        "outputId": "a19b3f8d-62c9-4230-c1b4-3d1ec245aaa2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9857, 0.0098],\n",
            "        [0.2819, 0.5824]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.4 $\\text{ElementWise Divsion of Tensors}$"
      ],
      "metadata": {
        "id": "htDxkaak7n55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2) # rand create a random tensor\n",
        "y = torch.ones(2,2, dtype=torch.int16) # creates a tensor of 1's\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLcgTqE07nSR",
        "outputId": "07558dfa-e81f-4b3d-dc44-a6283f12d710"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2207, 0.1528],\n",
            "        [0.9436, 0.0060]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x/y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3pYxHDj78KB",
        "outputId": "18bcab6e-098d-4062-8a2c-e999bb795df4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2207, 0.1528],\n",
            "        [0.9436, 0.0060]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.div(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSWYlCOU7_42",
        "outputId": "02c7bc35-7dc0-4c5e-9e3b-f632a3f92a16"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2207, 0.1528],\n",
            "        [0.9436, 0.0060]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.3 Slicing in Tensors}$"
      ],
      "metadata": {
        "id": "vEZeR8Vg8g0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpMa-2729asp",
        "outputId": "2e94a068-bef3-4c35-9d10-09f01e0651af"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8752, 0.1724, 0.4519, 0.5746, 0.4273])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1MBXUfY9je8",
        "outputId": "54a688a7-c235-4db1-ca71-b8b836e61dcd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4519, 0.5746, 0.4273])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPKhJg9c9pTM",
        "outputId": "d02b90fb-3dc9-42ae-b4a6-787e84ae64c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8752, 0.1724, 0.4519, 0.5746])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{Slicing a Multi-Dimensonal Tensors}$"
      ],
      "metadata": {
        "id": "aHCcwseO9zG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28dtuCKz-MZg",
        "outputId": "9ab8df75-871b-4327-e5a3-8fe99dbc5dfc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5295, 0.9874, 0.7660, 0.1589, 0.6280],\n",
            "        [0.8519, 0.7746, 0.8532, 0.2962, 0.1509],\n",
            "        [0.2955, 0.0214, 0.8900, 0.9579, 0.4471],\n",
            "        [0.7956, 0.1842, 0.0143, 0.4976, 0.8358]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1:,:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntaQPJUD-MLQ",
        "outputId": "e1705e1c-6051-490b-86cd-fc7b78ecd6a7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8519, 0.7746, 0.8532],\n",
              "        [0.2955, 0.0214, 0.8900],\n",
              "        [0.7956, 0.1842, 0.0143]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[2:4,3:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMOsts2_-eiB",
        "outputId": "ae541aa6-9d02-4301-bb2f-0045a7c58d0e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9579, 0.4471],\n",
              "        [0.4976, 0.8358]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $\\text{1.3.1 Indexing in tensor}$"
      ],
      "metadata": {
        "id": "TIKFay2L_Le7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tovTUqL-94x",
        "outputId": "f1195e67-141a-4821-a895-1eaff0a04bc6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5295)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{Getting the item at indexed element}$"
      ],
      "metadata": {
        "id": "Vk4Mv8eO_fN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk1sWOd7_BpS",
        "outputId": "80a991ef-44a9-4c86-f55f-a1381757eb97"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5294895768165588"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.4 Resize a Tensor}$"
      ],
      "metadata": {
        "id": "kHVh_q4R_w0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqKC4K-7AObN",
        "outputId": "1347110a-75bc-46ef-cd77-1f988d6d1499"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1825, 0.7086, 0.2069, 0.7937],\n",
            "        [0.3618, 0.5445, 0.1997, 0.6555],\n",
            "        [0.8051, 0.8078, 0.0491, 0.7145],\n",
            "        [0.5684, 0.2749, 0.6999, 0.8240]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(16)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXz9OyoQAT8T",
        "outputId": "9c99ff1b-ac99-4159-ba9b-87483e282f9d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1825, 0.7086, 0.2069, 0.7937, 0.3618, 0.5445, 0.1997, 0.6555, 0.8051,\n",
              "        0.8078, 0.0491, 0.7145, 0.5684, 0.2749, 0.6999, 0.8240])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(-1,2) # -1 gives it the required value for reshaping\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y40bPnALAYc3",
        "outputId": "49244a9a-3f17-4e4e-9df5-c27dc41cb45a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1825, 0.7086],\n",
            "        [0.2069, 0.7937],\n",
            "        [0.3618, 0.5445],\n",
            "        [0.1997, 0.6555],\n",
            "        [0.8051, 0.8078],\n",
            "        [0.0491, 0.7145],\n",
            "        [0.5684, 0.2749],\n",
            "        [0.6999, 0.8240]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.5 Numpy <=> Tensor}$"
      ],
      "metadata": {
        "id": "TNZQO0E6AODp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{1.5.1 Numpy => Tensor}$"
      ],
      "metadata": {
        "id": "-3tMD3BYCnRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ubq4_aejC2TK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5)\n",
        "print(x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02ho-QQKA55O",
        "outputId": "b6477085-d8c5-4b0d-98f1-650cdfd790a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7177, 0.2496, 0.2646, 0.3861, 0.4033])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = x.numpy()\n",
        "print(p)\n",
        "print(type(p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNYfKAjaA_bb",
        "outputId": "f0adae63-6d5f-439b-b357-b11c3bf58966"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7177494  0.2496109  0.2646472  0.38606107 0.40329653]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textbf{Caution !}$\n",
        "\n",
        "$\\text{Since, our tensor is on CPU and not GPU, both object x and p shares same memory location, then changing one will change other.}$"
      ],
      "metadata": {
        "id": "tYsO2xn4BL8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.add_(1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMjf1wOSBs_D",
        "outputId": "5b88d628-168b-4098-fe7f-ef9af7782088"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.7177, 1.2496, 1.2646, 1.3861, 1.4033])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ddac3tB9wy",
        "outputId": "f3abf4a0-1be9-4119-c4cd-d8a2750ef3dc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7177494 1.2496109 1.2646472 1.3860611 1.4032965]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Notice that: Changing 'x' also changed 'p' because they are sharing same memory location}$"
      ],
      "metadata": {
        "id": "FA-kFZg8CKqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\textbf{1.5.2 Numpy <= Tensor}$"
      ],
      "metadata": {
        "id": "-ByageLwCstX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.randn(5)\n",
        "print(a)\n",
        "print(type(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR5dcl1IC973",
        "outputId": "07d4c037-6730-434a-a56d-408dff8a8b9a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.13097374  0.21559439  0.3028324  -1.40084626  0.25022173]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(a)\n",
        "print(x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9UOA735DPw9",
        "outputId": "a7b184e1-67da-4b1d-e865-258a44d84ac2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1310,  0.2156,  0.3028, -1.4008,  0.2502], dtype=torch.float64)\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: Changing dtype of a tensor"
      ],
      "metadata": {
        "id": "e5_5zsIgEHaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before:\")\n",
        "print(x)\n",
        "x=x.to(dtype=torch.float16)\n",
        "print(\"\\nAfter:\")\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWFsEXwcDv1-",
        "outputId": "ed08d992-87cf-43e4-8fd4-1363a8e3c04d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "tensor([ 0.1310,  0.2156,  0.3028, -1.4008,  0.2502], dtype=torch.float64)\n",
            "\n",
            "After:\n",
            "tensor([ 0.1310,  0.2156,  0.3027, -1.4004,  0.2502], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{1.6 Creating Tensors on CUDA GPU}$"
      ],
      "metadata": {
        "id": "08WPL6plErtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lFrbWLxErKx",
        "outputId": "ccd60a17-55bd-4534-d3c9-071cff15f3c9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  # create directly on GPU\n",
        "  x = torch.ones(5, device = device)\n",
        "  # create on cpu then move to GPU\n",
        "  y = torch.zeros(5)\n",
        "  y = y.to(device=device)\n",
        "  z = x+y\n",
        "  z.numpy() #this will give error coz numpy can handle only cpu tensor"
      ],
      "metadata": {
        "id": "ST1YeNh2FC9Y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  x = torch.ones(5, device = device)\n",
        "  y = torch.zeros(5)\n",
        "  y = y.to(device=device)\n",
        "\n",
        "  z = x+y\n",
        "  print(z)\n",
        "  z = z.to(device=torch.device(\"cpu\"))\n",
        "  print(z)\n",
        "  z = z.numpy()\n",
        "  print(z)"
      ],
      "metadata": {
        "id": "IJU61d4AGZ7d"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $\\textbf{2. AutoGrad in Pytorch}$\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "PyTorch's $\\textbf{autograd}$ it is a tool that automatically calculates the gradients needed in the backpropagation step of learning models, particularly neural networks.\n",
        "\n",
        "- It works by creating a $\\textbf{dynamic computational graph}$ as you perform operations, which makes it very flexible and easy to debug.\n",
        "\n",
        "- To use autograd, you simply set **`requires_grad=True`** on the tensors you want to track. When you perform operations on these tensors, PyTorch keeps track of them. Later, you can call the $\\textbf{backward()}$ method on the final result to compute the gradients, which will be stored in the $\\textbf{.grad}$ attribute of the original tensors.\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{What is a computational graph?}$\n",
        "\n",
        " A computational graph is a dynamic representation of the operations (like addition, multiplication, etc.)  performed on tensors during the forward pass of a neural network.\n",
        "- a computational graph is typically represented as a $\\text{Directed Acyclic Graph (DAG)}$\n",
        "- In PyTorch, computational graphs are dynamic, meaning they are constructed dynamically as operations are performed during the execution of the forward pass.\n"
      ],
      "metadata": {
        "id": "FJOccEIBaQze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "kPiNHWkwaZFh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OoGIgEWejBt",
        "outputId": "55ffb679-40c3-406e-88b2-05bb69b676be"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1310, 1.2753, 1.2180])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Now suppose, Later sometime we will need to create the gradient of some function wrt. x, which we will do often while doing backprop while training a neural network.}$\n",
        "$\\text{For that we specify the argument }$**`requires_grad=True`**\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "-z99dgCafOda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24SKqAIjerNF",
        "outputId": "37d4ff8c-3493-4f16-9f74-73d0e740c0b1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3207, -0.0569, -1.6511], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Since we have enabled gradient calculation. Now, whenever we do any operation with tenor 'x' pytorch will create a computational graph for us.}$\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "921dyPwkghHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqiu3swRhVep",
        "outputId": "0de9b829-1928-4037-de5b-40dbb411b744"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.3207, 1.9431, 0.3489], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " $\\textbf{Note:}$ The $\\text{<AddBackward0>}$ indicates that the operation was **addition** and the $\\textbf{grad_fn}$ signifies that gradients can be computed for this tensor during backpropagation.\n",
        "\n",
        " <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "z23Y0NUTiqYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = x*y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Q981rfmGge",
        "outputId": "62e070cd-c3a8-4ddf-b679-76f66356dd9e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.7441, -0.1106, -0.5760], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w = z.sum()\n",
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7nMOIrunoj7",
        "outputId": "51a423b6-93d5-48e8-fd18-cb6610b09ca8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0575, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\textbf{2.2 Visualizing Computation Graph in PyTorch}$"
      ],
      "metadata": {
        "id": "F_EYGLSnjwf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torchviz -q # adding -q for quiet installation you can do without it aswell"
      ],
      "metadata": {
        "id": "GwxGEpq8iH4W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "make_dot(y, params={\"x\": x})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "YQDsUTllhfeL",
        "outputId": "8a8068c4-038b-40d1-82ce-1a3df3d919e6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"109pt\" height=\"215pt\"\n viewBox=\"0.00 0.00 109.00 215.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-211 105,-211 105,4 -4,4\"/>\n<!-- 133242748626128 -->\n<g id=\"node1\" class=\"node\">\n<title>133242748626128</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133242749062352 -->\n<g id=\"node2\" class=\"node\">\n<title>133242749062352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133242749062352&#45;&gt;133242748626128 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133242749062352&#45;&gt;133242748626128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 133242749061968 -->\n<g id=\"node3\" class=\"node\">\n<title>133242749061968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133242749061968&#45;&gt;133242749062352 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133242749061968&#45;&gt;133242749062352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 133242748637232 -->\n<g id=\"node4\" class=\"node\">\n<title>133242748637232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-207 23.5,-207 23.5,-177 77.5,-177 77.5,-207\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133242748637232&#45;&gt;133242749061968 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133242748637232&#45;&gt;133242749061968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.84C50.5,-169.21 50.5,-159.7 50.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.27 50.5,-141.27 47,-151.27 54,-151.27\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x792efeba0d00>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "make_dot(z, params={\"x\": x, 'y':y})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "4tpckzUPnutH",
        "outputId": "fa11360f-ef0d-4183-c368-f766c164175f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"140pt\" height=\"270pt\"\n viewBox=\"0.00 0.00 140.00 270.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 266)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-266 136,-266 136,4 -4,4\"/>\n<!-- 133242748543888 -->\n<g id=\"node1\" class=\"node\">\n<title>133242748543888</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133242749061200 -->\n<g id=\"node2\" class=\"node\">\n<title>133242749061200</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 133242749061200&#45;&gt;133242748543888 -->\n<g id=\"edge5\" class=\"edge\">\n<title>133242749061200&#45;&gt;133242748543888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 133242749061968 -->\n<g id=\"node3\" class=\"node\">\n<title>133242749061968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133242749061968&#45;&gt;133242749061200 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133242749061968&#45;&gt;133242749061200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M46.39,-176.88C42.44,-168.09 36.76,-153.94 34.5,-141 31.79,-125.43 36.74,-108.03 41.84,-95.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"45.13,-96.6 45.98,-86.04 38.73,-93.76 45.13,-96.6\"/>\n</g>\n<!-- 133242749062352 -->\n<g id=\"node5\" class=\"node\">\n<title>133242749062352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-141 43,-141 43,-122 132,-122 132,-141\"/>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133242749061968&#45;&gt;133242749062352 -->\n<g id=\"edge4\" class=\"edge\">\n<title>133242749061968&#45;&gt;133242749062352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.61,-176.75C61.78,-169.34 69.35,-158.5 75.69,-149.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-151.29 81.5,-141.09 72.91,-147.29 78.65,-151.29\"/>\n</g>\n<!-- 133242748637232 -->\n<g id=\"node4\" class=\"node\">\n<title>133242748637232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-262 23.5,-262 23.5,-232 77.5,-232 77.5,-262\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133242748637232&#45;&gt;133242749061968 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133242748637232&#45;&gt;133242749061968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.84C50.5,-224.21 50.5,-214.7 50.5,-206.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.27 50.5,-196.27 47,-206.27 54,-206.27\"/>\n</g>\n<!-- 133242749062352&#45;&gt;133242749061200 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133242749062352&#45;&gt;133242749061200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.39,-121.75C76.22,-114.34 68.65,-103.5 62.31,-94.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-92.29 56.5,-86.09 59.35,-96.29 65.09,-92.29\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x792efeba0ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "make_dot(w, params={\"x\": x, 'y':y, 'z':z})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "UF3VaWdYn2CS",
        "outputId": "0451ff22-05c7-4c97-a7fa-021b0dc8c2aa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"140pt\" height=\"325pt\"\n viewBox=\"0.00 0.00 140.00 325.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 321)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-321 136,-321 136,4 -4,4\"/>\n<!-- 133242748549888 -->\n<g id=\"node1\" class=\"node\">\n<title>133242748549888</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 133242749062784 -->\n<g id=\"node2\" class=\"node\">\n<title>133242749062784</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n</g>\n<!-- 133242749062784&#45;&gt;133242748549888 -->\n<g id=\"edge6\" class=\"edge\">\n<title>133242749062784&#45;&gt;133242748549888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n</g>\n<!-- 133242749061200 -->\n<g id=\"node3\" class=\"node\">\n<title>133242749061200</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 133242749061200&#45;&gt;133242749062784 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133242749061200&#45;&gt;133242749062784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n</g>\n<!-- 133242749061968 -->\n<g id=\"node4\" class=\"node\">\n<title>133242749061968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133242749061968&#45;&gt;133242749061200 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133242749061968&#45;&gt;133242749061200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M46.39,-231.88C42.44,-223.09 36.76,-208.94 34.5,-196 31.79,-180.43 36.74,-163.03 41.84,-150.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"45.13,-151.6 45.98,-141.04 38.73,-148.76 45.13,-151.6\"/>\n</g>\n<!-- 133242749062352 -->\n<g id=\"node6\" class=\"node\">\n<title>133242749062352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-196 43,-196 43,-177 132,-177 132,-196\"/>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 133242749061968&#45;&gt;133242749062352 -->\n<g id=\"edge5\" class=\"edge\">\n<title>133242749061968&#45;&gt;133242749062352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M56.61,-231.75C61.78,-224.34 69.35,-213.5 75.69,-204.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-206.29 81.5,-196.09 72.91,-202.29 78.65,-206.29\"/>\n</g>\n<!-- 133242748637232 -->\n<g id=\"node5\" class=\"node\">\n<title>133242748637232</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-317 23.5,-317 23.5,-287 77.5,-287 77.5,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 133242748637232&#45;&gt;133242749061968 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133242748637232&#45;&gt;133242749061968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 133242749062352&#45;&gt;133242749061200 -->\n<g id=\"edge4\" class=\"edge\">\n<title>133242749062352&#45;&gt;133242749061200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M81.39,-176.75C76.22,-169.34 68.65,-158.5 62.31,-149.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-147.29 56.5,-141.09 59.35,-151.29 65.09,-147.29\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x792efeba0e50>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\text{2.3 Gradient Calculation}$"
      ],
      "metadata": {
        "id": "pk_eB-VjnZCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform backpropagation\n",
        "w.backward()\n",
        "\n",
        "# Access the gradients of x\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Div_ziJPjlQE",
        "outputId": "de17993b-6d8b-44f9-e2bc-f7e73cade5a8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.6413,  1.8862, -1.3022])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "Calling $\\textbf{w.backward()}$ performs backpropagation to compute gradients of the tensor $\\textbf{w}$ with respect to the $\\textbf{leaf tensors}$ in the computational graph.\n",
        "\n",
        "<br>\n",
        "**Important Note:**\n",
        "\n",
        "PyTorch clears intermediate values of the computational graph by default after calling $\\textbf{backward()}$ to free up memory.\n",
        "- So, what happen if you try to do backprop again.\n",
        " - You will get error.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "R07sB7YrqZZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{2.3.1 Retaining Gradients after Backprop}$"
      ],
      "metadata": {
        "id": "mknFboKszPoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform backpropagation\n",
        "w.backward()\n",
        "\n",
        "# Access the gradients of x\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "NLnGPzjop11Z",
        "outputId": "b62a5c66-1ebd-470d-c9fc-b2696522f3ca"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-6733eb1135b5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Access the gradients of x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, If you need to perform multiple backward passes or access intermediate values of the graph after calling backward(), you should set **`retain_graph=True.`**"
      ],
      "metadata": {
        "id": "Au_b70pRs_sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5, requires_grad=True)\n",
        "y = x+2\n",
        "z = x*y\n",
        "w = z.sum()\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCqT5UEHtFYc",
        "outputId": "f5466982-42d4-42df-fdfe-2979c6c3c8f0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.1609, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.backward(retain_graph=True)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ653RfQtP2p",
        "outputId": "8d28308e-dbdc-4da6-ff8e-b39d0f890506"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.9094, -0.3271,  0.4224,  6.2061,  1.0076])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting ***`retain_graph=True`*** ensures that the computational graph is retained after the backward pass, allowing for multiple subsequent backward passes without needing to recompute the graph.\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{Lets do the backprop again}$"
      ],
      "metadata": {
        "id": "FR_vtAV-wQP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w.backward(retain_graph=True)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Koys9qGitV44",
        "outputId": "c30f19af-27fb-45c3-91ef-6a46aa4bc7d9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.8188, -0.6543,  0.8448, 12.4123,  2.0151])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{2.3.2 Getting Gradient of non-leaf tensors}$"
      ],
      "metadata": {
        "id": "qfg0yw_pxxSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrXgnifAwIqa",
        "outputId": "5d2df24a-dbb7-4a7a-a313-d00d13e76262"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-10b3a7061f6d>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The warning message you encountered indicates that you're trying to access the **`.grad`** attribute of a $\\text{non-leaf tensor }$  **(`y`)**.\n",
        "\n",
        "- By default, gradients of non-leaf tensors are not computed during the backward pass to save memory.\n",
        "\n",
        "- If you indeed want to compute gradients for a non-leaf tensor, you should call **`.retain_grad()`** on that tensor $\\text{before performing the backward pass.}$\n",
        "\n"
      ],
      "metadata": {
        "id": "JzN7Xi56xPoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "\n",
        "w.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubIRuNDnxPTw",
        "outputId": "1f2d8205-248b-4312-d0bd-3f44b92c9b7f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.7282, -0.9814,  1.2672, 18.6184,  3.0227])\n",
            "tensor([-1.4547, -1.1636, -0.7888,  2.1031, -0.4962])\n",
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{These gradients represent the sensitivity of the output 'w' to changes in each element of the respective tensors during backpropagation.}$"
      ],
      "metadata": {
        "id": "X2fYBEKyylgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can calcualte"
      ],
      "metadata": {
        "id": "6AeaBVwbvWpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w.backward(retain_graph=True)\n",
        "print(\"Gradient of x:\", x.grad)\n",
        "print(\"Gradient of y:\", y.grad)\n",
        "print(\"Gradient of z:\", z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZwyHSinuNdq",
        "outputId": "531aed41-b198-4d21-cd4d-452a9ca09a82"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x: tensor([-3.6376, -1.3085,  1.6895, 24.8245,  4.0302])\n",
            "Gradient of y: tensor([-2.9094, -2.3271, -1.5776,  4.2061, -0.9924])\n",
            "Gradient of z: tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{2.3.2 Prevent Gradient Tracking}$\n",
        "\n",
        "- **`x.requires_grad_(False)`**\n",
        "- **`x.detach()`**\n",
        "- **`with torch.no_grad()`**"
      ],
      "metadata": {
        "id": "ypPkd7bxWOm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqOqv_jNWB2U",
        "outputId": "8676ec96-467e-4a7d-eee6-8f75c45b4b2b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.1187, -0.5570,  0.9134], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x.requires_grad_(False) #modifies x inplace\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjQQl4FpYYjj",
        "outputId": "b5577e18-ec4f-4288-8234-db1b89b90f3e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.1187, -0.5570,  0.9134])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6alg4AsYkQu",
        "outputId": "7923cb7f-acbc-41b9-c35c-2c85ea5dcad7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4214,  1.3262, -0.4106], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y =x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01zB_LszYnLj",
        "outputId": "c03915dc-1ef1-4da0-a0c7-d5cd15aca327"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4214,  1.3262, -0.4106])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "with torch.no_grad():\n",
        "  y = x + 2\n",
        "  print(y)\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS4P26BKY-7x",
        "outputId": "2815cda7-74f8-4cce-d35a-174dd6c69bca"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4214,  1.3262, -0.4106], requires_grad=True)\n",
            "tensor([2.4214, 3.3262, 1.5894])\n",
            "tensor([ 0.4214,  1.3262, -0.4106], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Only operation on $x$ has been detached from gradient. $x$ still has gradient\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "pjV8YPCUZX-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $\\text{2.3.4 Gradient Accumulation}$\n",
        "\n",
        "Gradient accumulation involves accumulating gradients across multiple batches before updating the model parameters.\n",
        "\n",
        "- Instead of updating the parameters after processing each batch, gradients from each batch are added together over a certain number of batches or accumulation steps.\n",
        "- Once a sufficient number of gradients have been accumulated, the model parameters are updated based on the accumulated gradients.\n"
      ],
      "metadata": {
        "id": "IW8rzVN4aDMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(1):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMIMgMwfZD_A",
        "outputId": "dbed38d9-a0d1-49cf-adef-929dcda20e5c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UdThE6ibksy",
        "outputId": "b0d23efb-b984-4e6f-a91b-010de92b7fbc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9Jkxo7_btPB",
        "outputId": "f12c517f-8efd-4c96-9cbb-03d4d4e35c4e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    }
  ]
}
